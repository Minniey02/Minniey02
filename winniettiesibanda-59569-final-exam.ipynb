{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8453265,"sourceType":"datasetVersion","datasetId":5037956}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import RandomizedSearchCV\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-18T22:05:29.887948Z","iopub.execute_input":"2024-05-18T22:05:29.888342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the dataset\ndf = pd.read_csv('/kaggle/input/credit-scores-csv/credit_scores.csv')\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing the data\ndf = df.drop(columns=[\"Name\", \"SSN\", \"ID\", \"Customer_ID\"])\nX = df.drop('Credit_Score', axis=1)\ny = df['Credit_Score']\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividing the dataset into 80% training and 20% testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identifying numerical and categorical columns\nnum_cols = X_train.select_dtypes(include=np.number).columns.tolist()\ncat_cols = X_train.select_dtypes(exclude=np.number).columns.tolist()\n\n# Handling missing values and scale numerical columns\nnum_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())])\n\n# Handling missing values and convert categorical columns into numerical columns\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder())])\n\n# Combining preprocessing steps\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_transformer, num_cols),\n        ('cat', cat_transformer, cat_cols)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Developing a Support Vector Machine model\nmodel = SVC()\n\n# Create a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', model)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine-tunning hyperparameters\n# Defining the parameter grid\nparam_grid = {'classifier__kernel': ['rbf', 'linear'], 'classifier__C': [0.01, 10, 20]}\n\n# Using randomized search with a specified number of iterations\nrandom_search = RandomizedSearchCV(clf, param_grid, cv=5, n_iter=4, random_state=1)\nrandom_search.fit(X_train, y_train)\n\n# Reporting the accuracy of the best model\nprint(\"Best parameters: \", random_search.best_params_)\nprint(\"Best score: \", random_search.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retraining the best model using the whole dataset\nbest_model = random_search.best_estimator_\nbest_model.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating the score of the best model on training data\ntrain_score = best_model.score(X_train, y_train)\nprint(\"Training score: \", train_score)\n\n# Calculating the score of the best model on test data\ntest_score = best_model.score(X_test, y_test)\nprint(\"Test score: \", test_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the best model as a file\nfilename = 'credit_scores_MLproj.pkl'\n\n# Saving the model to disk\nwith open(filename, 'wb') as file:\n    pickle.dump(best_model, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}